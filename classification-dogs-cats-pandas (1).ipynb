{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing modules \nimport numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport cv2\n\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout\nfrom keras.models import Sequential\nimport tensorflow\n\nfrom sklearn.model_selection import train_test_split\n\nnp.random.seed(1)\n","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Processing training data\n# -> appending images in a list 'train_images'\n# -> appending labels in a list 'train_labels'\n\ntrain_images = []       \ntrain_labels = []\nshape = (200,200)  \ntrain_path = '../input/animals/animals/train/cats'\n\nfor filename in os.listdir('../input/animals/animals/train/cats'):\n    if filename.split('.')[1] == 'jpg':\n        img = cv2.imread(os.path.join(train_path,filename))\n        \n        # Spliting file names and storing the labels for image in list\n        train_labels.append(filename.split('_')[0])\n        \n        # Resize all images to a specific shape\n        img = cv2.resize(img,shape)\n        \n        train_images.append(img)\n\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '../input/animals/animals/train/dogs'\n\nfor filename in os.listdir('../input/animals/animals/train/dogs'):\n    if filename.split('.')[1] == 'jpg':\n        img = cv2.imread(os.path.join(train_path,filename))\n        \n        # Spliting file names and storing the labels for image in list\n        train_labels.append(filename.split('_')[0])\n        \n        # Resize all images to a specific shape\n        img = cv2.resize(img,shape)\n        \n        train_images.append(img)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '../input/animals/animals/train/panda'\n\nfor filename in os.listdir('../input/animals/animals/train/panda'):\n    if filename.split('.')[1] == 'jpg':\n        img = cv2.imread(os.path.join(train_path,filename))\n        \n        # Spliting file names and storing the labels for image in list\n        train_labels.append(filename.split('_')[0])\n        \n        # Resize all images to a specific shape\n        img = cv2.resize(img,shape)\n        \n        train_images.append(img)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.get_dummies(train_labels).values","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting train_images to array\ntrain_images = np.array(train_images)\n\n# Splitting Training data into train and validation dataset\nx_train,x_val,y_train,y_val = train_test_split(train_images,train_labels,random_state=1)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a Sequential model\nmodel= Sequential()\nmodel.add(Conv2D(kernel_size=(3,3), filters=32, activation='tanh', input_shape=(200,200,3)))\nmodel.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(20,activation='relu'))\nmodel.add(Dense(15,activation='relu'))\nmodel.add(Dense(3,activation = 'softmax'))\n    \nmodel.compile(\n              loss='categorical_crossentropy', \n              metrics=['acc'],\n              optimizer='adam'\n             )","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":8,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 198, 198, 32)      896       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 196, 196, 30)      8670      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 98, 98, 30)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 96, 96, 30)        8130      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 48, 48, 30)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 46, 46, 30)        8130      \n_________________________________________________________________\nflatten (Flatten)            (None, 63480)             0         \n_________________________________________________________________\ndense (Dense)                (None, 20)                1269620   \n_________________________________________________________________\ndense_1 (Dense)              (None, 15)                315       \n_________________________________________________________________\ndense_2 (Dense)              (None, 3)                 48        \n=================================================================\nTotal params: 1,295,809\nTrainable params: 1,295,809\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model\nhistory = model.fit(x_train,y_train,epochs=50,batch_size=50,validation_data=(x_val,y_val))","execution_count":9,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n40/40 [==============================] - 146s 4s/step - loss: 1.3887 - acc: 0.3837 - val_loss: 1.0982 - val_acc: 0.3529\nEpoch 2/50\n40/40 [==============================] - 144s 4s/step - loss: 1.1057 - acc: 0.3393 - val_loss: 1.1014 - val_acc: 0.3153\nEpoch 3/50\n40/40 [==============================] - 144s 4s/step - loss: 1.0966 - acc: 0.3508 - val_loss: 1.0993 - val_acc: 0.3153\nEpoch 4/50\n40/40 [==============================] - 145s 4s/step - loss: 1.0978 - acc: 0.3346 - val_loss: 1.0982 - val_acc: 0.3153\nEpoch 5/50\n40/40 [==============================] - 144s 4s/step - loss: 1.0947 - acc: 0.3309 - val_loss: 1.0831 - val_acc: 0.3153\nEpoch 6/50\n40/40 [==============================] - 144s 4s/step - loss: 1.0512 - acc: 0.4064 - val_loss: 0.9867 - val_acc: 0.5450\nEpoch 7/50\n40/40 [==============================] - 143s 4s/step - loss: 0.9621 - acc: 0.5475 - val_loss: 0.9341 - val_acc: 0.5240\nEpoch 8/50\n40/40 [==============================] - 144s 4s/step - loss: 0.9235 - acc: 0.5370 - val_loss: 0.9124 - val_acc: 0.5450\nEpoch 9/50\n40/40 [==============================] - 143s 4s/step - loss: 0.8638 - acc: 0.5594 - val_loss: 0.9086 - val_acc: 0.5480\nEpoch 10/50\n40/40 [==============================] - 144s 4s/step - loss: 0.8268 - acc: 0.5764 - val_loss: 0.8835 - val_acc: 0.5270\nEpoch 11/50\n40/40 [==============================] - 144s 4s/step - loss: 0.8498 - acc: 0.5559 - val_loss: 0.8504 - val_acc: 0.5465\nEpoch 12/50\n40/40 [==============================] - 144s 4s/step - loss: 0.8299 - acc: 0.5541 - val_loss: 0.8552 - val_acc: 0.5435\nEpoch 13/50\n40/40 [==============================] - 156s 4s/step - loss: 0.8295 - acc: 0.5837 - val_loss: 0.9406 - val_acc: 0.5165\nEpoch 14/50\n40/40 [==============================] - 146s 4s/step - loss: 0.8096 - acc: 0.5744 - val_loss: 0.8365 - val_acc: 0.5586\nEpoch 15/50\n40/40 [==============================] - 146s 4s/step - loss: 0.7682 - acc: 0.5979 - val_loss: 0.8244 - val_acc: 0.5511\nEpoch 16/50\n40/40 [==============================] - 146s 4s/step - loss: 0.7804 - acc: 0.5791 - val_loss: 0.8404 - val_acc: 0.5495\nEpoch 17/50\n40/40 [==============================] - 155s 4s/step - loss: 0.7879 - acc: 0.5813 - val_loss: 0.8425 - val_acc: 0.5435\nEpoch 18/50\n40/40 [==============================] - 155s 4s/step - loss: 0.7760 - acc: 0.5857 - val_loss: 0.8080 - val_acc: 0.5526\nEpoch 19/50\n40/40 [==============================] - 146s 4s/step - loss: 0.7909 - acc: 0.5811 - val_loss: 0.8144 - val_acc: 0.5495\nEpoch 20/50\n40/40 [==============================] - 147s 4s/step - loss: 0.7469 - acc: 0.5923 - val_loss: 0.8133 - val_acc: 0.5586\nEpoch 21/50\n40/40 [==============================] - 146s 4s/step - loss: 0.7761 - acc: 0.5853 - val_loss: 0.7849 - val_acc: 0.5661\nEpoch 22/50\n40/40 [==============================] - 158s 4s/step - loss: 0.7208 - acc: 0.6171 - val_loss: 0.7802 - val_acc: 0.5616\nEpoch 23/50\n40/40 [==============================] - 147s 4s/step - loss: 0.7220 - acc: 0.6063 - val_loss: 0.8057 - val_acc: 0.5571\nEpoch 24/50\n40/40 [==============================] - 148s 4s/step - loss: 0.7439 - acc: 0.5951 - val_loss: 0.8367 - val_acc: 0.5435\nEpoch 25/50\n40/40 [==============================] - 147s 4s/step - loss: 0.7255 - acc: 0.6100 - val_loss: 0.7933 - val_acc: 0.5616\nEpoch 26/50\n40/40 [==============================] - 158s 4s/step - loss: 0.7073 - acc: 0.5970 - val_loss: 0.7873 - val_acc: 0.5586\nEpoch 27/50\n40/40 [==============================] - 148s 4s/step - loss: 0.7027 - acc: 0.6133 - val_loss: 0.8293 - val_acc: 0.5511\nEpoch 28/50\n40/40 [==============================] - 147s 4s/step - loss: 0.6974 - acc: 0.6146 - val_loss: 0.8160 - val_acc: 0.5631\nEpoch 29/50\n40/40 [==============================] - 148s 4s/step - loss: 0.7065 - acc: 0.6092 - val_loss: 0.8460 - val_acc: 0.5450\nEpoch 30/50\n40/40 [==============================] - 166s 4s/step - loss: 0.7487 - acc: 0.5908 - val_loss: 0.7783 - val_acc: 0.5826\nEpoch 31/50\n40/40 [==============================] - 147s 4s/step - loss: 0.6731 - acc: 0.6289 - val_loss: 0.9218 - val_acc: 0.5180\nEpoch 32/50\n40/40 [==============================] - 148s 4s/step - loss: 0.7730 - acc: 0.5810 - val_loss: 0.8110 - val_acc: 0.5676\nEpoch 33/50\n40/40 [==============================] - 147s 4s/step - loss: 0.7160 - acc: 0.6120 - val_loss: 0.9194 - val_acc: 0.4970\nEpoch 34/50\n40/40 [==============================] - 159s 4s/step - loss: 0.7481 - acc: 0.6026 - val_loss: 1.0364 - val_acc: 0.5060\nEpoch 35/50\n40/40 [==============================] - 147s 4s/step - loss: 0.8156 - acc: 0.5762 - val_loss: 0.8303 - val_acc: 0.5586\nEpoch 36/50\n40/40 [==============================] - 148s 4s/step - loss: 0.8085 - acc: 0.5661 - val_loss: 0.7782 - val_acc: 0.5691\nEpoch 37/50\n40/40 [==============================] - 147s 4s/step - loss: 0.7048 - acc: 0.6024 - val_loss: 0.8295 - val_acc: 0.5541\nEpoch 38/50\n40/40 [==============================] - 159s 4s/step - loss: 0.6990 - acc: 0.6147 - val_loss: 0.7623 - val_acc: 0.5751\nEpoch 39/50\n40/40 [==============================] - 147s 4s/step - loss: 0.6855 - acc: 0.6057 - val_loss: 0.7649 - val_acc: 0.5811\nEpoch 40/50\n40/40 [==============================] - 149s 4s/step - loss: 0.6583 - acc: 0.6472 - val_loss: 0.7525 - val_acc: 0.5706\nEpoch 41/50\n40/40 [==============================] - 149s 4s/step - loss: 0.6740 - acc: 0.6159 - val_loss: 0.7630 - val_acc: 0.5736\nEpoch 42/50\n40/40 [==============================] - 168s 4s/step - loss: 0.6669 - acc: 0.6378 - val_loss: 0.7782 - val_acc: 0.5736\nEpoch 43/50\n40/40 [==============================] - 148s 4s/step - loss: 0.7006 - acc: 0.6356 - val_loss: 0.8030 - val_acc: 0.5601\nEpoch 44/50\n40/40 [==============================] - 149s 4s/step - loss: 0.6579 - acc: 0.6289 - val_loss: 0.9056 - val_acc: 0.5601\nEpoch 45/50\n40/40 [==============================] - 147s 4s/step - loss: 0.6996 - acc: 0.6224 - val_loss: 0.7630 - val_acc: 0.5796\nEpoch 46/50\n40/40 [==============================] - 163s 4s/step - loss: 0.6392 - acc: 0.6577 - val_loss: 0.7651 - val_acc: 0.5796\nEpoch 47/50\n40/40 [==============================] - 148s 4s/step - loss: 0.6460 - acc: 0.6357 - val_loss: 0.7793 - val_acc: 0.5691\nEpoch 48/50\n40/40 [==============================] - 148s 4s/step - loss: 0.6138 - acc: 0.6704 - val_loss: 0.7888 - val_acc: 0.5631\nEpoch 49/50\n40/40 [==============================] - 150s 4s/step - loss: 0.5980 - acc: 0.6529 - val_loss: 0.8224 - val_acc: 0.5495\nEpoch 50/50\n40/40 [==============================] - 149s 4s/step - loss: 0.6547 - acc: 0.6443 - val_loss: 0.9003 - val_acc: 0.5240\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Processing testing data\n# -> appending images in a list 'test_images'\n# -> appending labels in a list 'test_labels'\n# The test data contains labels as well also we are appending it to a list but we are'nt going to use it while training.\n\ntest_images = []\ntest_labels = []\nshape = (200,200)\ntest_path = '../input/animals/animals/test/cats'\n\nfor filename in os.listdir('../input/animals/animals/test/cats'):\n    if filename.split('.')[1] == 'jpg':\n        img = cv2.imread(os.path.join(test_path,filename))\n        \n        # Spliting file names and storing the labels for image in list\n        test_labels.append(filename.split('_')[0])\n        \n        # Resize all images to a specific shape\n        img = cv2.resize(img,shape)\n        \n        test_images.append(img)\n        \n","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Processing testing data\n# -> appending images in a list 'test_images'\n# -> appending labels in a list 'test_labels'\n# The test data contains labels as well also we are appending it to a list but we are'nt going to use it while training.\n\n\ntest_path = '../input/animals/animals/test/dogs'\n\nfor filename in os.listdir('../input/animals/animals/test/dogs'):\n    if filename.split('.')[1] == 'jpg':\n        img = cv2.imread(os.path.join(test_path,filename))\n        \n        # Spliting file names and storing the labels for image in list\n        test_labels.append(filename.split('_')[0])\n        \n        # Resize all images to a specific shape\n        img = cv2.resize(img,shape)\n        \n        test_images.append(img)\n        \n","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Processing testing data\n# -> appending images in a list 'test_images'\n# -> appending labels in a list 'test_labels'\n# The test data contains labels as well also we are appending it to a list but we are'nt going to use it while training.\n\n\ntest_path = '../input/animals/animals/test/panda'\n\nfor filename in os.listdir('../input/animals/animals/test/panda'):\n    if filename.split('.')[1] == 'jpg':\n        img = cv2.imread(os.path.join(test_path,filename))\n        \n        # Spliting file names and storing the labels for image in list\n        test_labels.append(filename.split('_')[0])\n        \n        # Resize all images to a specific shape\n        img = cv2.resize(img,shape)\n        \n        test_images.append(img)\n        \n# Converting test_images to array\n","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = np.array(test_images)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict(np.array(test_images))\noutput = { 0:'cats',1:'dogs',2:'panda'}\n","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict\n","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"array([[0.5164894 , 0.4620107 , 0.02149991],\n       [0.5164894 , 0.4620107 , 0.02149991],\n       [0.5164894 , 0.4620107 , 0.02149991],\n       ...,\n       [0.04226075, 0.09839494, 0.8593443 ],\n       [0.01784912, 0.05184827, 0.93030256],\n       [0.04239664, 0.09862696, 0.8589764 ]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"final = []","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in predict:\n    final.append(output[np.argmax(i)])","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final\n","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"['cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'dogs',\n 'cats',\n 'dogs',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'dogs',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'panda',\n 'cats',\n 'panda',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'dogs',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'dogs',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'dogs',\n 'cats',\n 'cats',\n 'dogs',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'dogs',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'panda',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'dogs',\n 'cats',\n 'dogs',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'panda',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'dogs',\n 'dogs',\n 'panda',\n 'panda',\n 'cats',\n 'panda',\n 'dogs',\n 'panda',\n 'dogs',\n 'dogs',\n 'panda',\n 'panda',\n 'dogs',\n 'panda',\n 'dogs',\n 'panda',\n 'dogs',\n 'dogs',\n 'panda',\n 'panda',\n 'panda',\n 'dogs',\n 'dogs',\n 'panda',\n 'panda',\n 'panda',\n 'cats',\n 'dogs',\n 'dogs',\n 'panda',\n 'cats',\n 'panda',\n 'dogs',\n 'cats',\n 'panda',\n 'panda',\n 'panda',\n 'cats',\n 'dogs',\n 'panda',\n 'panda',\n 'panda',\n 'dogs',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'dogs',\n 'dogs',\n 'cats',\n 'cats',\n 'dogs',\n 'dogs',\n 'panda',\n 'dogs',\n 'panda',\n 'panda',\n 'cats',\n 'cats',\n 'panda',\n 'panda',\n 'dogs',\n 'panda',\n 'panda',\n 'cats',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'dogs',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'dogs',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'dogs',\n 'panda',\n 'dogs',\n 'cats',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'dogs',\n 'panda',\n 'cats',\n 'cats',\n 'dogs',\n 'panda',\n 'cats',\n 'cats',\n 'cats',\n 'panda',\n 'panda',\n 'cats',\n 'cats',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"['cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'cats',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'dogs',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda',\n 'panda']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'Class': final})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"     Class\n0     cats\n1     cats\n2     cats\n3     cats\n4     cats\n..     ...\n331  panda\n332  panda\n333  panda\n334  panda\n335  panda\n\n[336 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cats</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cats</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cats</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cats</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cats</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>panda</td>\n    </tr>\n    <tr>\n      <th>332</th>\n      <td>panda</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>panda</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>panda</td>\n    </tr>\n    <tr>\n      <th>335</th>\n      <td>panda</td>\n    </tr>\n  </tbody>\n</table>\n<p>336 rows Ã— 1 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}